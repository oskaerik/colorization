{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform, color\n",
    "from colorize import network, util, dataset\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"data/**/*.jpg\")[:1000]\n",
    "\n",
    "# Show some random images\n",
    "for path in np.random.choice(images, 3, replace=False):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    # Show original\n",
    "    L, ab = util.imread(path)\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    util.imshow(L, ab)\n",
    "    \n",
    "    # Show encoded/decoded\n",
    "    Y = transform.resize(ab, (56, 56))\n",
    "    Z = util.soft_encode(Y)\n",
    "    Y_decoded = util.decode(Z)\n",
    "    Y_decoded = transform.resize(Y_decoded, (224, 224))\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    util.imshow(L, Y_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 32,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "epochs = 5\n",
    "\n",
    "data = dataset.Dataset(images)\n",
    "dataloader = torch.utils.data.DataLoader(data, **params)\n",
    "\n",
    "net = network.Network()\n",
    "net.to(device)\n",
    "util.w = util.w.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch, (X, Z) in enumerate(dataloader, start=1):\n",
    "        X, Z = X.to(device), Z.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Z_hat = net(X)\n",
    "        loss = util.multinomial_cross_entropy_loss(Z_hat, Z)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}/{epochs}, Loss: {running_loss / batch}')\n",
    "    torch.save(net.state_dict(), f'models/model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colorize a batch\n",
    "for X, Z in dataloader:\n",
    "    X = X.to(device)\n",
    "    Z_hat = net(X)\n",
    "    \n",
    "    X = X.cpu().data.numpy()\n",
    "    Z_hat = Z_hat.cpu().data.numpy()\n",
    "    \n",
    "    for i, _ in enumerate(X):\n",
    "        X_img = util.reshape(X[i:i+1], 3)[0] * 50 + 50\n",
    "        Z_hat_img = util.reshape(Z_hat[i:i+1], 3)[0]\n",
    "        Y_img = util.decode(Z_hat_img)\n",
    "        Y_img = transform.resize(Y_img, (224, 224))\n",
    "        plt.figure()\n",
    "        util.imshow(X_img, Y_img)\n",
    "        plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
